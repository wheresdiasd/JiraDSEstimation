{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for the compare_models function in the regression module\n",
    "# Replace the compare_models function with this version\n",
    "\n",
    "def compare_models(self, all_results):\n",
    "    \"\"\"Compare global model with cluster-specific models\"\"\"\n",
    "    if not all_results['clusters']:\n",
    "        print(\"No cluster models to compare with global model.\")\n",
    "        return\n",
    "        \n",
    "    # Create comparison dataframe\n",
    "    comparison_data = []\n",
    "    \n",
    "    # Add global model\n",
    "    global_metrics = all_results['global']['metrics']\n",
    "    comparison_data.append({\n",
    "        'Model': 'Global',\n",
    "        'RMSE': global_metrics['RMSE'],\n",
    "        'MAE': global_metrics['MAE'],\n",
    "        'R²': global_metrics['R²'],\n",
    "        'MMRE': global_metrics['MMRE']\n",
    "    })\n",
    "    \n",
    "    # Add cluster models\n",
    "    for cluster_id, results in all_results['clusters'].items():\n",
    "        metrics = results['metrics']\n",
    "        # Convert cluster id to string to avoid numeric conversion issues\n",
    "        cluster_name = f'Cluster_{cluster_id}'\n",
    "        comparison_data.append({\n",
    "            'Model': cluster_name,  \n",
    "            'RMSE': metrics['RMSE'],\n",
    "            'MAE': metrics['MAE'],\n",
    "            'R²': metrics['R²'],\n",
    "            'MMRE': metrics['MMRE']\n",
    "        })\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Calculate average metrics for cluster models\n",
    "    cluster_metrics = comparison_df[comparison_df['Model'] != 'Global']\n",
    "    avg_metrics = {\n",
    "        'RMSE': cluster_metrics['RMSE'].mean(),\n",
    "        'MAE': cluster_metrics['MAE'].mean(),\n",
    "        'R²': cluster_metrics['R²'].mean(),\n",
    "        'MMRE': cluster_metrics['MMRE'].mean()\n",
    "    }\n",
    "    \n",
    "    # Get global metrics\n",
    "    global_row = comparison_df[comparison_df['Model'] == 'Global'].iloc[0]\n",
    "    \n",
    "    # Calculate improvement\n",
    "    rmse_improvement = ((global_row['RMSE'] - avg_metrics['RMSE']) / global_row['RMSE']) * 100\n",
    "    r2_improvement = ((avg_metrics['R²'] - global_row['R²']) / max(0.0001, abs(global_row['R²']))) * 100\n",
    "    mmre_improvement = ((global_row['MMRE'] - avg_metrics['MMRE']) / max(0.0001, global_row['MMRE'])) * 100\n",
    "    \n",
    "    print(\"\\nPerformance Comparison:\")\n",
    "    print(f\"Global model: RMSE={global_row['RMSE']:.4f}, R²={global_row['R²']:.4f}, MMRE={global_row['MMRE']:.4f}\")\n",
    "    print(f\"Cluster avg.: RMSE={avg_metrics['RMSE']:.4f}, R²={avg_metrics['R²']:.4f}, MMRE={avg_metrics['MMRE']:.4f}\")\n",
    "    print(f\"Improvement:  RMSE={rmse_improvement:.1f}%, R²={r2_improvement:.1f}%, MMRE={mmre_improvement:.1f}%\")\n",
    "    \n",
    "    # Create comparison plots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # RMSE plot (lower is better)\n",
    "    sns.barplot(data=comparison_df, x='Model', y='RMSE', ax=axes[0])\n",
    "    axes[0].set_title('RMSE Comparison (lower is better)')\n",
    "    axes[0].set_ylabel('RMSE')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # R² plot (higher is better)\n",
    "    sns.barplot(data=comparison_df, x='Model', y='R²', ax=axes[1])\n",
    "    axes[1].set_title('R² Comparison (higher is better)')\n",
    "    axes[1].set_ylabel('R²')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # MMRE plot (lower is better)\n",
    "    sns.barplot(data=comparison_df, x='Model', y='MMRE', ax=axes[2])\n",
    "    axes[2].set_title('MMRE Comparison (lower is better)')\n",
    "    axes[2].set_ylabel('MMRE')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(self.plots_dir, 'model_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save comparison to CSV\n",
    "    comparison_df.to_csv(os.path.join(self.plots_dir, 'model_comparison.csv'), index=False)\n",
    "    \n",
    "    # Add summary row\n",
    "    comparison_df.loc[len(comparison_df)] = [\n",
    "        'Cluster Average', \n",
    "        avg_metrics['RMSE'], \n",
    "        avg_metrics['MAE'],\n",
    "        avg_metrics['R²'],\n",
    "        avg_metrics['MMRE']\n",
    "    ]\n",
    "    \n",
    "    return comparison_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
