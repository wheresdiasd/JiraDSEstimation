{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (1575833, 63)\n",
      "Reduced dataset shape (10%): (78792, 63)\n",
      "\n",
      "Fields to exclude that exist in the dataframe: ['fields.status.name', 'fields.project.key', 'fields.priority.name', 'fields.project.name']\n",
      "Dropping these fields from the dataframe: ['fields.status.name', 'fields.project.key', 'fields.priority.name', 'fields.project.name']\n",
      "Dataframe shape after dropping: (78792, 59)\n",
      "Missing values in target: 0\n",
      "Dataset shape after dropping missing targets: (78792, 59)\n",
      "\n",
      "Using 57 numeric features for correlation calculation\n",
      "Top 10 correlated features with target:\n",
      "count_std__total_issues                 0.862916\n",
      "remainder__team_size_creators           0.756246\n",
      "remainder__team_size_combined           0.756246\n",
      "time_power__project_duration_days       0.436095\n",
      "stat_robust__bug_ratio                  0.295816\n",
      "pct_minmax__type_bug_pct                0.264590\n",
      "avg_resolution_hours                    0.258526\n",
      "stat_robust__weighted_priority_score    0.187998\n",
      "age_days                                0.152002\n",
      "pct_minmax__priority_blocker_pct        0.144445\n",
      "Name: total_resolution_hours, dtype: float64\n",
      "\n",
      "Bottom 10 correlated features with target:\n",
      "created_year                              -0.151671\n",
      "pct_minmax__type_story_pct                -0.170015\n",
      "pct_minmax__type_epic_pct                 -0.213995\n",
      "pct_minmax__type_task_pct                 -0.281289\n",
      "project_id                                -0.283082\n",
      "stat_robust__high_to_low_priority_ratio   -0.284235\n",
      "pct_minmax__type_new_feature_pct          -0.357708\n",
      "fields.created                                  NaN\n",
      "fields.updated                                  NaN\n",
      "remainder__team_size_assignees                  NaN\n",
      "Name: total_resolution_hours, dtype: float64\n",
      "\n",
      "Features with >0.8 correlation with target: ['count_std__total_issues']\n",
      "\n",
      "Removing suspicious features: ['avg_resolution_hours', 'median_resolution_hours', 'resolution_hours', 'log_resolution_hours', 'fields.status.name', 'fields.project.key', 'fields.priority.name', 'fields.project.name']\n",
      "Available features: 42\n",
      "Missing features: 0\n",
      "\n",
      "Checking for fields that need to be dropped:\n",
      "Field 'fields.status.name' does not exist in the dataframe\n",
      "Field 'fields.project.key' does not exist in the dataframe\n",
      "Field 'fields.priority.name' does not exist in the dataframe\n",
      "Field 'fields.project.name' does not exist in the dataframe\n",
      "\n",
      "Confirming excluded fields:\n",
      "'fields.status.name' is NOT in the feature list\n",
      "'fields.project.key' is NOT in the feature list\n",
      "'fields.priority.name' is NOT in the feature list\n",
      "'fields.project.name' is NOT in the feature list\n",
      "\n",
      "Using 42 numeric features for multicollinearity check\n",
      "\n",
      "High correlation pairs (>0.95):\n",
      "priority_id - fields.priority.id: 1.0000\n",
      "issue_type_id - fields.issuetype.id: 1.0000\n",
      "is_type_bug - type_bug: 1.0000\n",
      "is_type_task - type_task: 1.0000\n",
      "is_type_sub-task - type_sub_task: 1.0000\n",
      "remainder__team_size_combined - remainder__team_size_creators: 1.0000\n",
      "stat_robust__bug_ratio - pct_minmax__type_bug_pct: 0.9607\n",
      "\n",
      "Dropping features due to multicollinearity: ['fields.priority.id', 'fields.issuetype.id', 'type_bug', 'type_task', 'type_sub_task', 'remainder__team_size_creators', 'pct_minmax__type_bug_pct']\n",
      "Final feature count: 35\n",
      "\n",
      "Final confirmation - excluded fields:\n",
      "'fields.status.name' is NOT in the final feature list\n",
      "'fields.project.key' is NOT in the final feature list\n",
      "'fields.priority.name' is NOT in the final feature list\n",
      "'fields.project.name' is NOT in the final feature list\n",
      "\n",
      "Final verification before model training:\n",
      "Target variable: total_resolution_hours\n",
      "Number of features: 35\n",
      "Verified: Target is not being used as a feature\n",
      "Performing 5-fold cross-validation...\n",
      "Random_Forest CV R² scores: [0.9604349  0.9596374  0.94933509 0.95219655 0.95634557]\n",
      "Random_Forest CV R² mean: 0.9556, std: 0.0043\n",
      "Gradient_Boosting CV R² scores: [0.96948889 0.9697794  0.97398553 0.97220085 0.97053931]\n",
      "Gradient_Boosting CV R² mean: 0.9712, std: 0.0017\n",
      "XGBoost CV R² scores: [0.96753976 0.96797998 0.96937016 0.9682146  0.96690707]\n",
      "XGBoost CV R² mean: 0.9680, std: 0.0008\n",
      "\n",
      "Training Random_Forest...\n",
      "Random_Forest - MAE: 699979.68, RMSE: 1018064.33, R2: 0.9539, Spearman: 0.9301\n",
      "\n",
      "Training Gradient_Boosting...\n",
      "Gradient_Boosting - MAE: 488155.87, RMSE: 780393.48, R2: 0.9729, Spearman: 0.9328\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost - MAE: 536858.75, RMSE: 843225.60, R2: 0.9684, Spearman: 0.9306\n",
      "Ensemble - MAE: 559290.87, RMSE: 845587.26, R2: 0.9682, Spearman: 0.9322\n",
      "Best model based on MAE: Gradient_Boosting\n",
      "Top 10 most important features:\n",
      "                                    Feature  Importance\n",
      "30            remainder__team_size_combined    0.700709\n",
      "19                pct_minmax__type_task_pct    0.049237\n",
      "31     stat_robust__weighted_priority_score    0.045431\n",
      "33  stat_robust__high_to_low_priority_ratio    0.037156\n",
      "20         pct_minmax__type_new_feature_pct    0.025398\n",
      "32          stat_robust__issue_type_entropy    0.025340\n",
      "21                pct_minmax__type_epic_pct    0.023998\n",
      "25        pct_minmax__priority_critical_pct    0.020287\n",
      "26         pct_minmax__priority_blocker_pct    0.019778\n",
      "22         pct_minmax__type_improvement_pct    0.015925\n",
      "Calculating correlations for top 10 numeric features\n",
      "\n",
      "Model Summary:\n",
      "==============\n",
      "We've created an improved ensemble model to predict resolution hours for Jira issues. The improvements include:\n",
      "1. Removing features with potential data leakage (high correlation with target)\n",
      "2. Addressing multicollinearity by removing highly correlated features\n",
      "3. Using cross-validation to get more reliable performance estimates\n",
      "4. Applying more conservative hyperparameters to prevent overfitting\n",
      "5. Adding residual plots to better understand model errors\n",
      "6. Including Spearman rank correlation as a metric less affected by outliers\n",
      "7. Removing project and status specific features to prevent overfitting to specific projects\n",
      "\n",
      "This improved model provides more realistic estimates and better generalization to new data.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Resolution Hours Ensemble Model - Improved\n",
    "# \n",
    "# This notebook creates a more realistic ensemble model to predict total resolution hours for Jira issues.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'merged_task_data/merged_project_task_data.csv'\n",
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "\n",
    "# Convert string columns that should be numeric\n",
    "for col in df.columns:\n",
    "    if col.startswith('fields.issuetype') or col.startswith('fields.priority'):\n",
    "        # Keep these as string/categorical\n",
    "        continue\n",
    "    try:\n",
    "        # Try converting to numeric, coerce errors to NaN\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    except:\n",
    "        # If conversion fails completely, leave as is\n",
    "        pass\n",
    "\n",
    "# Use only 10% of the data for faster processing\n",
    "df = df.sample(frac=0.05, random_state=42)\n",
    "print(f\"Reduced dataset shape (10%): {df.shape}\")\n",
    "\n",
    "# Define target variable - to be used only as the target, never as a feature\n",
    "target_variable = 'total_resolution_hours'\n",
    "\n",
    "# Define fields that must be excluded\n",
    "fields_to_exclude = ['fields.status.name', 'fields.project.key', 'fields.priority.name', 'fields.project.name']\n",
    "\n",
    "# Check which of these fields actually exist in the dataframe\n",
    "existing_fields_to_exclude = [field for field in fields_to_exclude if field in df.columns]\n",
    "print(f\"\\nFields to exclude that exist in the dataframe: {existing_fields_to_exclude}\")\n",
    "\n",
    "# Remove the fields from the dataframe itself to avoid correlation errors\n",
    "if existing_fields_to_exclude:\n",
    "    print(f\"Dropping these fields from the dataframe: {existing_fields_to_exclude}\")\n",
    "    df = df.drop(columns=existing_fields_to_exclude)\n",
    "    print(f\"Dataframe shape after dropping: {df.shape}\")\n",
    "\n",
    "# Check for missing values in the target variable\n",
    "print(f\"Missing values in target: {df[target_variable].isna().sum()}\")\n",
    "\n",
    "# Drop rows with missing target values\n",
    "df = df.dropna(subset=[target_variable])\n",
    "print(f\"Dataset shape after dropping missing targets: {df.shape}\")\n",
    "\n",
    "# Plot distribution of target variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df[target_variable].clip(0, 500), bins=50)\n",
    "plt.title('Distribution of Total Resolution Hours (clipped at 500 for visibility)')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Count')\n",
    "os.makedirs('task_estimation_results_improved', exist_ok=True)\n",
    "plt.savefig('task_estimation_results_improved/target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Identify numeric columns for correlation analysis\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "# Exclude target from potential features\n",
    "numeric_features = [col for col in numeric_columns if col != target_variable]\n",
    "print(f\"\\nUsing {len(numeric_features)} numeric features for correlation calculation\")\n",
    "\n",
    "# Calculate correlations between features and target\n",
    "if target_variable in df.columns and numeric_features:\n",
    "    # Create a dataframe with just the features and target for correlation\n",
    "    corr_df = df[numeric_features + [target_variable]]\n",
    "    target_correlations = corr_df.corr()[target_variable].drop(target_variable).sort_values(ascending=False)\n",
    "    \n",
    "    print(\"Top 10 correlated features with target:\")\n",
    "    print(target_correlations.head(10))\n",
    "    print(\"\\nBottom 10 correlated features with target:\")\n",
    "    print(target_correlations.tail(10))\n",
    "    \n",
    "    # Print all features that have correlation > 0.8 with target\n",
    "    high_corr_features = target_correlations[target_correlations > 0.8].index.tolist()\n",
    "    print(f\"\\nFeatures with >0.8 correlation with target: {high_corr_features}\")\n",
    "else:\n",
    "    print(\"Cannot calculate target correlations - either target or features missing\")\n",
    "    high_corr_features = []\n",
    "    \n",
    "# Define suspicious features (features that may lead to data leakage)\n",
    "suspicious_features = [\n",
    "    # Resolution-related features that would leak the target information\n",
    "    'avg_resolution_hours', 'median_resolution_hours', \n",
    "    'resolution_hours', 'log_resolution_hours'\n",
    "]\n",
    "\n",
    "# Add highly correlated features to suspicious list\n",
    "suspicious_features.extend(high_corr_features)\n",
    "\n",
    "# Add excluded fields to suspicious list\n",
    "suspicious_features.extend(fields_to_exclude)\n",
    "\n",
    "\n",
    "# Make sure target variable is not in suspicious features list (it's our target, not a feature)\n",
    "if target_variable in suspicious_features:\n",
    "    suspicious_features.remove(target_variable)\n",
    "    \n",
    "print(f\"\\nRemoving suspicious features: {suspicious_features}\")\n",
    "\n",
    "# Original features list, excluding suspicious features\n",
    "features = [\n",
    "    'fields.issuetype.id', 'fields.priority.id', 'priority_id', 'issue_type_id',\n",
    "    'type_task', 'type_bug', 'inward_count', 'outward_count', 'type_sub_task',\n",
    "    'created_hour', 'created_month', 'created_year',\n",
    "    'is_type_bug', 'is_type_task', 'is_type_story', 'is_type_improvement',\n",
    "    'is_type_new_feature', 'is_type_epic', 'is_type_sub-task',\n",
    "    'is_priority_blocker', 'is_priority_critical', 'is_priority_major',\n",
    "    'is_priority_minor', 'is_priority_trivial',\n",
    "    'pct_minmax__type_bug_pct', 'pct_minmax__type_task_pct',\n",
    "    'pct_minmax__type_new_feature_pct', 'pct_minmax__type_epic_pct',\n",
    "    'pct_minmax__type_improvement_pct', 'pct_minmax__type_story_pct',\n",
    "    'pct_minmax__type_documentation_pct', 'pct_minmax__priority_critical_pct',\n",
    "    'pct_minmax__priority_blocker_pct', 'pct_minmax__priority_high_pct',\n",
    "    'pct_minmax__priority_low_pct',\n",
    "    'remainder__team_size_creators', 'remainder__team_size_assignees',\n",
    "    'remainder__team_size_combined',\n",
    "    'stat_robust__weighted_priority_score', 'stat_robust__issue_type_entropy',\n",
    "    'stat_robust__high_to_low_priority_ratio', 'stat_robust__bug_ratio'\n",
    "]\n",
    "\n",
    "# Ensure we exclude the additional fields by checking if they exist in the dataset\n",
    "for field in fields_to_exclude:\n",
    "    if field in df.columns and field not in suspicious_features:\n",
    "        suspicious_features.append(field)\n",
    "        print(f\"Added {field} to suspicious features list\")\n",
    "\n",
    "# Filter dataset to include only features available in our dataset and not in suspicious list\n",
    "available_features = [f for f in features if f in df.columns and f not in suspicious_features]\n",
    "missing_features = [f for f in features if f not in df.columns]\n",
    "\n",
    "print(f\"Available features: {len(available_features)}\")\n",
    "print(f\"Missing features: {len(missing_features)}\")\n",
    "if missing_features:\n",
    "    print(f\"Missing feature list: {missing_features}\")\n",
    "    \n",
    "# Make absolutely sure we're not using the target as a feature\n",
    "if target_variable in available_features:\n",
    "    available_features.remove(target_variable)\n",
    "    print(f\"WARNING: Removed target variable '{target_variable}' from features list\")\n",
    "    \n",
    "# Explicitly check all fields that need to be dropped\n",
    "print(\"\\nChecking for fields that need to be dropped:\")\n",
    "for field in fields_to_exclude:\n",
    "    if field in df.columns:\n",
    "        print(f\"Field '{field}' exists in the dataframe\")\n",
    "        if field in available_features:\n",
    "            available_features.remove(field)\n",
    "            print(f\"-> Removed '{field}' from available features\")\n",
    "    else:\n",
    "        print(f\"Field '{field}' does not exist in the dataframe\")\n",
    "\n",
    "# Double-check if any of these fields might be in the final feature list\n",
    "for field in fields_to_exclude:\n",
    "    if field in available_features:\n",
    "        available_features.remove(field)\n",
    "        print(f\"-> Explicitly removed '{field}' from available features\")\n",
    "        \n",
    "# Print final confirmation\n",
    "print(\"\\nConfirming excluded fields:\")\n",
    "for field in fields_to_exclude:\n",
    "    print(f\"'{field}' is {'NOT' if field not in available_features else 'STILL'} in the feature list\")\n",
    "\n",
    "# Check for multicollinearity\n",
    "# Use only numeric features for correlation calculation\n",
    "numeric_available_features = [f for f in available_features if f in numeric_features]\n",
    "print(f\"\\nUsing {len(numeric_available_features)} numeric features for multicollinearity check\")\n",
    "\n",
    "if len(numeric_available_features) > 0:\n",
    "    # Verify one more time we don't have the target as a feature\n",
    "    if target_variable in numeric_available_features:\n",
    "        numeric_available_features.remove(target_variable)\n",
    "        print(f\"WARNING: Removed target variable from multicollinearity calculation\")\n",
    "    \n",
    "    correlation_matrix = df[numeric_available_features].corr().abs()\n",
    "    upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool_))\n",
    "    high_corr_pairs = [(col1, col2) for col1 in upper_tri.columns for col2 in upper_tri.index if upper_tri.loc[col2, col1] > 0.95]\n",
    "\n",
    "    print(f\"\\nHigh correlation pairs (>0.95):\")\n",
    "    for col1, col2 in high_corr_pairs:\n",
    "        print(f\"{col1} - {col2}: {upper_tri.loc[col2, col1]:.4f}\")\n",
    "    \n",
    "    # Optionally remove one of each highly correlated pair\n",
    "    features_to_drop = []\n",
    "    for col1, col2 in high_corr_pairs:\n",
    "        # Keep the first one, drop the second one\n",
    "        if col2 not in features_to_drop:\n",
    "            features_to_drop.append(col2)\n",
    "\n",
    "    print(f\"\\nDropping features due to multicollinearity: {features_to_drop}\")\n",
    "else:\n",
    "    print(\"No numeric features available for multicollinearity check\")\n",
    "    features_to_drop = []\n",
    "\n",
    "final_features = [f for f in available_features if f not in features_to_drop]\n",
    "print(f\"Final feature count: {len(final_features)}\")\n",
    "\n",
    "# Final check to ensure we've dropped the specified fields\n",
    "for field in fields_to_exclude:\n",
    "    if field in final_features:\n",
    "        final_features.remove(field)\n",
    "        print(f\"Final check: Removed '{field}' from final_features\")\n",
    "        \n",
    "# Print confirmation of fields not in final features\n",
    "print(\"\\nFinal confirmation - excluded fields:\")\n",
    "for field in fields_to_exclude:\n",
    "    present = field in final_features\n",
    "    print(f\"'{field}' is {'STILL in' if present else 'NOT in'} the final feature list\")\n",
    "\n",
    "# Prepare the data\n",
    "X = df[final_features].copy()\n",
    "y = df[target_variable]  # The target variable\n",
    "\n",
    "# Fill any remaining NaN values with median\n",
    "for col in X.columns:\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# Split the data with stratification on binned target to ensure similar distributions\n",
    "y_binned = pd.qcut(y, q=10, duplicates='drop')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y_binned)\n",
    "\n",
    "# Final verification: ensure target is not used as a feature\n",
    "print(\"\\nFinal verification before model training:\")\n",
    "print(f\"Target variable: {target_variable}\")\n",
    "print(f\"Number of features: {len(final_features)}\")\n",
    "if target_variable in final_features:\n",
    "    print(f\"ERROR: Target variable found in feature list!\")\n",
    "    final_features.remove(target_variable)\n",
    "    X = df[final_features].copy()  # Recreate X without the target\n",
    "    print(f\"Removed target from features. New feature count: {len(final_features)}\")\n",
    "    \n",
    "    # Re-split with corrected features\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y_binned)\n",
    "else:\n",
    "    print(\"Verified: Target is not being used as a feature\")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save data splits for later reference\n",
    "with open('task_estimation_results_improved/data_splits.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'feature_names': final_features,\n",
    "        'scaler': scaler\n",
    "    }, f)\n",
    "\n",
    "# Define the models with more conservative hyperparameters to prevent overfitting\n",
    "models = {\n",
    "    'Random_Forest': RandomForestRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=10,\n",
    "        min_samples_leaf=5,\n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Gradient_Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=5, \n",
    "        learning_rate=0.05,\n",
    "        min_child_weight=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Perform cross-validation to get more reliable performance estimates\n",
    "print(\"Performing 5-fold cross-validation...\")\n",
    "for name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    print(f\"{name} CV R² scores: {cv_scores}\")\n",
    "    print(f\"{name} CV R² mean: {cv_scores.mean():.4f}, std: {cv_scores.std():.4f}\")\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    predictions[name] = y_pred\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    spearman_corr, _ = spearmanr(y_test, y_pred)  # Rank correlation, less affected by outliers\n",
    "    \n",
    "    results[name] = {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'Spearman': spearman_corr\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.4f}, Spearman: {spearman_corr:.4f}\")\n",
    "    \n",
    "    # Save the model\n",
    "    with open(f'task_estimation_results_improved/{name}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "    plt.plot([0, y_test.max()], [0, y_test.max()], 'r--')\n",
    "    plt.xlabel('Actual Hours')\n",
    "    plt.ylabel('Predicted Hours')\n",
    "    plt.title(f'{name} - Actual vs Predicted')\n",
    "    plt.savefig(f'task_estimation_results_improved/{name}_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Add residual subplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    residuals = y_test - y_pred\n",
    "    plt.scatter(y_pred, residuals, alpha=0.3)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Predicted Hours')\n",
    "    plt.ylabel('Residuals (Actual - Predicted)')\n",
    "    plt.title(f'{name} - Residual Plot')\n",
    "    plt.savefig(f'task_estimation_results_improved/{name}_residuals.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Create an ensemble prediction by averaging the predictions\n",
    "ensemble_pred = np.mean([predictions[name] for name in models.keys()], axis=0)\n",
    "\n",
    "# Calculate metrics for the ensemble\n",
    "ensemble_mae = mean_absolute_error(y_test, ensemble_pred)\n",
    "ensemble_rmse = np.sqrt(mean_squared_error(y_test, ensemble_pred))\n",
    "ensemble_r2 = r2_score(y_test, ensemble_pred)\n",
    "ensemble_spearman, _ = spearmanr(y_test, ensemble_pred)\n",
    "\n",
    "print(f\"Ensemble - MAE: {ensemble_mae:.2f}, RMSE: {ensemble_rmse:.2f}, R2: {ensemble_r2:.4f}, Spearman: {ensemble_spearman:.4f}\")\n",
    "\n",
    "# Plot actual vs predicted for ensemble\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, ensemble_pred, alpha=0.3)\n",
    "plt.plot([0, y_test.max()], [0, y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Hours')\n",
    "plt.ylabel('Predicted Hours')\n",
    "plt.title('Ensemble - Actual vs Predicted')\n",
    "plt.savefig('task_estimation_results_improved/Ensemble_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Plot residuals for ensemble\n",
    "plt.figure(figsize=(10, 6))\n",
    "ensemble_residuals = y_test - ensemble_pred\n",
    "plt.scatter(ensemble_pred, ensemble_residuals, alpha=0.3)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Hours')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title('Ensemble - Residual Plot')\n",
    "plt.savefig('task_estimation_results_improved/Ensemble_residuals.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Identify the best model\n",
    "best_model_name = min(results, key=lambda x: results[x]['MAE'])\n",
    "best_model = models[best_model_name]\n",
    "print(f\"Best model based on MAE: {best_model_name}\")\n",
    "\n",
    "# Save the best model as the one to use for predictions\n",
    "with open('task_estimation_results_improved/best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Plot feature importance for the best model\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Get feature importances\n",
    "    importances = best_model.feature_importances_\n",
    "    \n",
    "    # Sort features by importance\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Plot the top 20 features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(f'Feature Importance - {best_model_name}')\n",
    "    plt.bar(range(min(20, len(final_features))), \n",
    "            importances[indices[:20]], \n",
    "            align='center')\n",
    "    plt.xticks(range(min(20, len(final_features))), \n",
    "               [final_features[i] for i in indices[:20]], \n",
    "               rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('task_estimation_results_improved/best_model_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a DataFrame for easier analysis\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': final_features,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 10 most important features:\")\n",
    "    print(feature_importance_df.head(10))\n",
    "\n",
    "    # Calculate and plot correlations between top features and the target\n",
    "    top_features = [f for f in feature_importance_df['Feature'].head(10).tolist() if f in numeric_features]\n",
    "    if top_features:\n",
    "        # Final check that we don't include the target in the correlation matrix\n",
    "        if target_variable in top_features:\n",
    "            top_features.remove(target_variable)\n",
    "            print(f\"WARNING: Removed target from top features correlation\")\n",
    "            \n",
    "        print(f\"Calculating correlations for top {len(top_features)} numeric features\")\n",
    "        if top_features:\n",
    "            corr_columns = top_features + [target_variable]\n",
    "            corr_data = df[corr_columns].copy()\n",
    "            \n",
    "            plt.figure(figsize=(12, 10))\n",
    "            sns.heatmap(corr_data.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "            plt.title('Correlation Between Top Features and Target')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('task_estimation_results_improved/top_features_correlation.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(\"No valid top features remain for correlation analysis\")\n",
    "    else:\n",
    "        print(\"No numeric top features available for correlation analysis\")\n",
    "\n",
    "    # Group feature importance by categories\n",
    "    # Define categories based on feature name prefixes\n",
    "    categories = {\n",
    "        'Issue Type': [f for f in final_features if 'type_' in f or 'is_type_' in f],\n",
    "        'Priority': [f for f in final_features if 'priority' in f],\n",
    "        'Project Stats': [f for f in final_features if 'count_' in f or 'pct_' in f],\n",
    "        'Team Size': [f for f in final_features if 'team_size' in f],\n",
    "        'Created Time': [f for f in final_features if 'created_' in f],\n",
    "        'Robust Stats': [f for f in final_features if 'stat_robust' in f],\n",
    "        'Other': []\n",
    "    }\n",
    "    \n",
    "    # Assign remaining features to 'Other'\n",
    "    for feature in final_features:\n",
    "        if not any(feature in cat_features for cat_features in categories.values()):\n",
    "            categories['Other'].append(feature)\n",
    "    \n",
    "    # Calculate importance by category\n",
    "    category_importance = {}\n",
    "    for category, cat_features in categories.items():\n",
    "        if cat_features:  # Skip empty categories\n",
    "            total_importance = sum(feature_importance_df.loc[feature_importance_df['Feature'].isin(cat_features), 'Importance'])\n",
    "            category_importance[category] = total_importance\n",
    "    \n",
    "    # Plot category importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    categories_sorted = sorted(category_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    categories_names = [item[0] for item in categories_sorted]\n",
    "    categories_values = [item[1] for item in categories_sorted]\n",
    "    \n",
    "    plt.bar(categories_names, categories_values)\n",
    "    plt.xlabel('Feature Category')\n",
    "    plt.ylabel('Total Importance')\n",
    "    plt.title('Feature Importance by Category')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('task_estimation_results_improved/best_model_feature_importance_by_category.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Plot actual vs predicted in task_results folder for overall project view\n",
    "os.makedirs('task_results_improved', exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, predictions[best_model_name], alpha=0.3)\n",
    "plt.plot([0, y_test.max()], [0, y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Hours')\n",
    "plt.ylabel('Predicted Hours')\n",
    "plt.title(f'Best Model ({best_model_name}) - Actual vs Predicted')\n",
    "plt.savefig('task_results_improved/actual_vs_predicted.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Plot feature importance in task_results folder\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(f'Feature Importance - {best_model_name}')\n",
    "    plt.bar(range(min(20, len(final_features))), \n",
    "            importances[indices[:20]], \n",
    "            align='center')\n",
    "    plt.xticks(range(min(20, len(final_features))), \n",
    "               [final_features[i] for i in indices[:20]], \n",
    "               rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('task_results_improved/task_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "print(\"==============\")\n",
    "print(\"We've created an improved ensemble model to predict resolution hours for Jira issues. The improvements include:\")\n",
    "print(\"1. Removing features with potential data leakage (high correlation with target)\")\n",
    "print(\"2. Addressing multicollinearity by removing highly correlated features\")\n",
    "print(\"3. Using cross-validation to get more reliable performance estimates\")\n",
    "print(\"4. Applying more conservative hyperparameters to prevent overfitting\")\n",
    "print(\"5. Adding residual plots to better understand model errors\")\n",
    "print(\"6. Including Spearman rank correlation as a metric less affected by outliers\")\n",
    "print(\"7. Removing project and status specific features to prevent overfitting to specific projects\")\n",
    "print(\"\\nThis improved model provides more realistic estimates and better generalization to new data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_mongo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
