{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "# Create output directory for visualizations\n",
    "viz_dir = 'enhanced_model_evaluation'\n",
    "os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('./processed_data/common_features.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. TARGET VARIABLE PREPARATION\n",
    "# --------------------------------------------------\n",
    "target = 'total_resolution_hours'\n",
    "df['log_total_resolution_hours'] = np.log1p(df[target])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. PLANNING-TIME FEATURES\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Define features available at planning time (excluding project_duration_days)\n",
    "planning_features = [\n",
    "    # Project scope indicators\n",
    "    'total_issues',                    # Estimated during planning\n",
    "    \n",
    "    # Project composition estimates\n",
    "    'priority_critical_pct',           # Expected critical issues\n",
    "    'priority_high_pct',               # Expected high priority issues\n",
    "    'priority_medium_pct',             # Expected medium priority issues\n",
    "    'priority_low_pct',                # Expected low priority issues\n",
    "    'priority_blocker_pct',            # Expected blocker issues\n",
    "    \n",
    "    # Issue type distribution (estimated from similar projects)\n",
    "    'type_bug_pct',                    # Expected bug percentage\n",
    "    'type_task_pct',                   # Expected task percentage\n",
    "    'type_new_feature_pct',            # Expected feature work\n",
    "    'type_improvement_pct',            # Expected improvements\n",
    "    'type_documentation_pct',          # Expected documentation work\n",
    "    \n",
    "    # Team composition\n",
    "    'team_size_creators',              # Planned team size\n",
    "    'team_size_assignees',             # Planned assignees\n",
    "    'team_size_combined',              # Overall team size\n",
    "    \n",
    "    # Complexity indicators\n",
    "    'weighted_priority_score',         # Expected priority complexity\n",
    "    'issue_type_entropy',              # Expected variety of issues\n",
    "    \n",
    "    # Historical indicators that could be estimated\n",
    "    'high_to_low_priority_ratio',      # Expected priority distribution\n",
    "    'bug_ratio',                       # Expected bug ratio\n",
    "]\n",
    "\n",
    "# Filter to features that exist in the dataframe\n",
    "planning_features = [f for f in planning_features if f in df.columns]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. DATA PREPARATION\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Prepare the data for modeling\n",
    "df_planning = df[planning_features + ['log_total_resolution_hours', target]].copy()\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df_planning.isnull().sum()\n",
    "print(\"\\nMissing values per feature:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Handle missing values with imputation\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_planning[planning_features] = imputer.fit_transform(df_planning[planning_features])\n",
    "\n",
    "# Check for and replace infinite values\n",
    "for col in planning_features:\n",
    "    mask = np.isinf(df_planning[col])\n",
    "    if mask.any():\n",
    "        print(f\"Replacing {mask.sum()} infinite values in {col}\")\n",
    "        df_planning.loc[mask, col] = df_planning[col].median()\n",
    "\n",
    "# Split data into features and target\n",
    "X = df_planning[planning_features]\n",
    "y_log = df_planning['log_total_resolution_hours']\n",
    "y_original = df_planning[target]\n",
    "\n",
    "# Scale features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_log_train, y_log_test, y_orig_train, y_orig_test = train_test_split(\n",
    "    X_scaled, y_log, y_original, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. MODEL TRAINING\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Train Ridge Regression model (on log-transformed target)\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_log_train)\n",
    "\n",
    "# Train Random Forest model (on log-transformed target)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_log_train)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. MODEL EVALUATION WITH MULTIPLE METRICS\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Function to calculate comprehensive metrics\n",
    "def calculate_metrics(y_true, y_pred, y_true_orig=None, y_pred_orig=None, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Calculate and print comprehensive error metrics for model evaluation.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Actual values (log-transformed)\n",
    "        y_pred: Predicted values (log-transformed)\n",
    "        y_true_orig: Actual values (original scale)\n",
    "        y_pred_orig: Predicted values (original scale)\n",
    "        model_name: Name of the model for display\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Calculate metrics in log space\n",
    "    metrics['rmse_log'] = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    metrics['mae_log'] = mean_absolute_error(y_true, y_pred)\n",
    "    metrics['r2_log'] = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Error distribution analysis\n",
    "    errors = y_true - y_pred\n",
    "    metrics['error_mean'] = np.mean(errors)\n",
    "    metrics['error_std'] = np.std(errors)\n",
    "    metrics['error_skew'] = stats.skew(errors)\n",
    "    metrics['error_kurtosis'] = stats.kurtosis(errors)\n",
    "    \n",
    "    # Metrics in original scale (if provided)\n",
    "    if y_true_orig is not None and y_pred_orig is not None:\n",
    "        metrics['rmse_original'] = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))\n",
    "        metrics['mae_original'] = mean_absolute_error(y_true_orig, y_pred_orig)\n",
    "        metrics['r2_original'] = r2_score(y_true_orig, y_pred_orig)\n",
    "        \n",
    "        # MAPE (Mean Absolute Percentage Error)\n",
    "        # Handle zero or near-zero values in the denominator\n",
    "        mape = np.mean(np.abs((y_true_orig - y_pred_orig) / (y_true_orig + 1e-10))) * 100\n",
    "        metrics['mape'] = mape\n",
    "        \n",
    "        # SMAPE (Symmetric Mean Absolute Percentage Error)\n",
    "        # Less sensitive to small denominators\n",
    "        smape = 100 * np.mean(2 * np.abs(y_pred_orig - y_true_orig) / \n",
    "                            (np.abs(y_true_orig) + np.abs(y_pred_orig) + 1e-10))\n",
    "        metrics['smape'] = smape\n",
    "    \n",
    "    # Print metrics summary\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"Log Space - RMSE: {metrics['rmse_log']:.4f}, MAE: {metrics['mae_log']:.4f}, R²: {metrics['r2_log']:.4f}\")\n",
    "    print(f\"Error Distribution - Mean: {metrics['error_mean']:.4f}, Std: {metrics['error_std']:.4f}\")\n",
    "    print(f\"Error Distribution - Skew: {metrics['error_skew']:.4f}, Kurtosis: {metrics['error_kurtosis']:.4f}\")\n",
    "    \n",
    "    if y_true_orig is not None and y_pred_orig is not None:\n",
    "        print(f\"Original Scale - RMSE: {metrics['rmse_original']:.4f}, MAE: {metrics['mae_original']:.4f}\")\n",
    "        print(f\"Percentage Errors - MAPE: {metrics['mape']:.2f}%, SMAPE: {metrics['smape']:.2f}%\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Make predictions (log space)\n",
    "ridge_pred_log = ridge_model.predict(X_test)\n",
    "rf_pred_log = rf_model.predict(X_test)\n",
    "\n",
    "# Transform predictions back to original scale\n",
    "ridge_pred_orig = np.expm1(ridge_pred_log)\n",
    "rf_pred_orig = np.expm1(rf_pred_log)\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "ridge_metrics = calculate_metrics(y_log_test, ridge_pred_log, y_orig_test, ridge_pred_orig, \"Ridge Regression\")\n",
    "rf_metrics = calculate_metrics(y_log_test, rf_pred_log, y_orig_test, rf_pred_orig, \"Random Forest\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. ERROR DISTRIBUTION ANALYSIS\n",
    "# --------------------------------------------------\n",
    "\n",
    "# As suggested by the Chai & Draxler paper, checking error distribution is important\n",
    "# to determine if RMSE or MAE is more appropriate\n",
    "\n",
    "# Create error distribution plots\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Ridge model errors\n",
    "plt.subplot(1, 2, 1)\n",
    "ridge_errors = y_log_test - ridge_pred_log\n",
    "sns.histplot(ridge_errors, kde=True, color='steelblue')\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "plt.title('Ridge Model Error Distribution', fontsize=14)\n",
    "plt.xlabel('Error (Actual - Predicted)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "\n",
    "# Add normal distribution fit\n",
    "mu, std = np.mean(ridge_errors), np.std(ridge_errors)\n",
    "x = np.linspace(mu - 3*std, mu + 3*std, 100)\n",
    "p = stats.norm.pdf(x, mu, std)\n",
    "plt.plot(x, p * len(ridge_errors) * (plt.gca().get_xlim()[1] - plt.gca().get_xlim()[0]) / 10, \n",
    "         'r-', linewidth=2, label=f'Normal Fit\\nμ={mu:.2f}, σ={std:.2f}')\n",
    "plt.legend()\n",
    "\n",
    "# Random Forest model errors\n",
    "plt.subplot(1, 2, 2)\n",
    "rf_errors = y_log_test - rf_pred_log\n",
    "sns.histplot(rf_errors, kde=True, color='forestgreen')\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "plt.title('Random Forest Error Distribution', fontsize=14)\n",
    "plt.xlabel('Error (Actual - Predicted)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "\n",
    "# Add normal distribution fit\n",
    "mu, std = np.mean(rf_errors), np.std(rf_errors)\n",
    "x = np.linspace(mu - 3*std, mu + 3*std, 100)\n",
    "p = stats.norm.pdf(x, mu, std)\n",
    "plt.plot(x, p * len(rf_errors) * (plt.gca().get_xlim()[1] - plt.gca().get_xlim()[0]) / 10, \n",
    "         'r-', linewidth=2, label=f'Normal Fit\\nμ={mu:.2f}, σ={std:.2f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{viz_dir}/error_distributions.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 7. QUANTILE-QUANTILE PLOTS FOR NORMALITY\n",
    "# --------------------------------------------------\n",
    "\n",
    "# As noted in the paper, normality of errors determines whether RMSE is appropriate\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Ridge model Q-Q plot\n",
    "plt.subplot(1, 2, 1)\n",
    "stats.probplot(ridge_errors, dist=\"norm\", plot=plt)\n",
    "plt.title('Ridge Model Q-Q Plot', fontsize=14)\n",
    "\n",
    "# Random Forest model Q-Q plot\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(rf_errors, dist=\"norm\", plot=plt)\n",
    "plt.title('Random Forest Model Q-Q Plot', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{viz_dir}/qq_plots.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 8. RMSE/MAE RATIO ANALYSIS\n",
    "# --------------------------------------------------\n",
    "\n",
    "# The paper mentions that RMSE/MAE ratio gives insights into error distribution\n",
    "ridge_rmse_mae_ratio_log = ridge_metrics['rmse_log'] / ridge_metrics['mae_log']\n",
    "rf_rmse_mae_ratio_log = rf_metrics['rmse_log'] / rf_metrics['mae_log']\n",
    "\n",
    "ridge_rmse_mae_ratio_orig = ridge_metrics['rmse_original'] / ridge_metrics['mae_original']\n",
    "rf_rmse_mae_ratio_orig = rf_metrics['rmse_original'] / rf_metrics['mae_original']\n",
    "\n",
    "print(\"\\nRMSE/MAE Ratio Analysis:\")\n",
    "print(f\"Ridge - Log Space: {ridge_rmse_mae_ratio_log:.2f}, Original Space: {ridge_rmse_mae_ratio_orig:.2f}\")\n",
    "print(f\"RF - Log Space: {rf_rmse_mae_ratio_log:.2f}, Original Space: {rf_rmse_mae_ratio_orig:.2f}\")\n",
    "print(\"Note: Ratio closer to 1 indicates more uniform error distribution\")\n",
    "print(\"      Higher ratio indicates presence of larger errors (RMSE more sensitive)\")\n",
    "\n",
    "# Create ratio comparison plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "models = ['Ridge', 'Random Forest']\n",
    "log_ratios = [ridge_rmse_mae_ratio_log, rf_rmse_mae_ratio_log]\n",
    "orig_ratios = [ridge_rmse_mae_ratio_orig, rf_rmse_mae_ratio_orig]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, log_ratios, width, label='Log Space', color='steelblue')\n",
    "plt.bar(x + width/2, orig_ratios, width, label='Original Space', color='forestgreen')\n",
    "\n",
    "plt.ylabel('RMSE/MAE Ratio', fontsize=12)\n",
    "plt.title('RMSE/MAE Ratio by Model and Space', fontsize=14)\n",
    "plt.xticks(x, models, fontsize=12)\n",
    "plt.axhline(y=1, color='red', linestyle='--', alpha=0.7, label='Uniform Error Reference')\n",
    "plt.legend()\n",
    "\n",
    "# Add ratio values on bars\n",
    "for i, v in enumerate(log_ratios):\n",
    "    plt.text(i - width/2, v + 0.1, f'{v:.2f}', ha='center', fontsize=10)\n",
    "\n",
    "for i, v in enumerate(orig_ratios):\n",
    "    plt.text(i + width/2, v + 0.1, f'{v:.2f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{viz_dir}/rmse_mae_ratio.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 9. ACTUAL VS PREDICTED VISUALIZATIONS\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Create scatter plots in log space\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Ridge Model - Log Space\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(y_log_test, ridge_pred_log, alpha=0.6, color='steelblue')\n",
    "plt.plot([y_log_test.min(), y_log_test.max()], [y_log_test.min(), y_log_test.max()], 'r--')\n",
    "plt.title('Ridge: Actual vs Predicted (Log Space)', fontsize=14)\n",
    "plt.xlabel('Actual Log(Total Resolution Hours)', fontsize=12)\n",
    "plt.ylabel('Predicted Log(Total Resolution Hours)', fontsize=12)\n",
    "plt.annotate(f'RMSE = {ridge_metrics[\"rmse_log\"]:.4f}\\nMAE = {ridge_metrics[\"mae_log\"]:.4f}\\nR² = {ridge_metrics[\"r2_log\"]:.4f}', \n",
    "             xy=(0.05, 0.85), xycoords='axes fraction', fontsize=12)\n",
    "\n",
    "# Random Forest - Log Space\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(y_log_test, rf_pred_log, alpha=0.6, color='forestgreen')\n",
    "plt.plot([y_log_test.min(), y_log_test.max()], [y_log_test.min(), y_log_test.max()], 'r--')\n",
    "plt.title('Random Forest: Actual vs Predicted (Log Space)', fontsize=14)\n",
    "plt.xlabel('Actual Log(Total Resolution Hours)', fontsize=12)\n",
    "plt.ylabel('Predicted Log(Total Resolution Hours)', fontsize=12)\n",
    "plt.annotate(f'RMSE = {rf_metrics[\"rmse_log\"]:.4f}\\nMAE = {rf_metrics[\"mae_log\"]:.4f}\\nR² = {rf_metrics[\"r2_log\"]:.4f}', \n",
    "             xy=(0.05, 0.85), xycoords='axes fraction', fontsize=12)\n",
    "\n",
    "# Ridge Model - Original Space (with axis limits to handle extreme values)\n",
    "plt.subplot(2, 2, 3)\n",
    "max_val = np.percentile(np.concatenate([y_orig_test, ridge_pred_orig]), 95)  # Use 95th percentile to limit extreme values\n",
    "plt.scatter(y_orig_test, ridge_pred_orig, alpha=0.6, color='steelblue')\n",
    "plt.plot([0, max_val], [0, max_val], 'r--')\n",
    "plt.title('Ridge: Actual vs Predicted (Original Space)', fontsize=14)\n",
    "plt.xlabel('Actual Total Resolution Hours', fontsize=12)\n",
    "plt.ylabel('Predicted Total Resolution Hours', fontsize=12)\n",
    "plt.xlim(0, max_val)\n",
    "plt.ylim(0, max_val)\n",
    "plt.annotate(f'RMSE = {ridge_metrics[\"rmse_original\"]:.4f}\\nMAE = {ridge_metrics[\"mae_original\"]:.4f}\\nMAPE = {ridge_metrics[\"mape\"]:.2f}%', \n",
    "             xy=(0.05, 0.85), xycoords='axes fraction', fontsize=12)\n",
    "\n",
    "# Random Forest - Original Space (with axis limits to handle extreme values)\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(y_orig_test, rf_pred_orig, alpha=0.6, color='forestgreen')\n",
    "plt.plot([0, max_val], [0, max_val], 'r--')\n",
    "plt.title('Random Forest: Actual vs Predicted (Original Space)', fontsize=14)\n",
    "plt.xlabel('Actual Total Resolution Hours', fontsize=12)\n",
    "plt.ylabel('Predicted Total Resolution Hours', fontsize=12)\n",
    "plt.xlim(0, max_val)\n",
    "plt.ylim(0, max_val)\n",
    "plt.annotate(f'RMSE = {rf_metrics[\"rmse_original\"]:.4f}\\nMAE = {rf_metrics[\"mae_original\"]:.4f}\\nMAPE = {rf_metrics[\"mape\"]:.2f}%', \n",
    "             xy=(0.05, 0.85), xycoords='axes fraction', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{viz_dir}/actual_vs_predicted_comparison.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 10. ERROR MAGNITUDE ANALYSIS\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Create error magnitude plots\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Ridge model absolute errors vs actual values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_log_test, np.abs(ridge_errors), alpha=0.6, color='steelblue')\n",
    "plt.title('Ridge: Error Magnitude vs Actual Value', fontsize=14)\n",
    "plt.xlabel('Actual Log(Total Resolution Hours)', fontsize=12)\n",
    "plt.ylabel('Absolute Error', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Random Forest absolute errors vs actual values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_log_test, np.abs(rf_errors), alpha=0.6, color='forestgreen')\n",
    "plt.title('Random Forest: Error Magnitude vs Actual Value', fontsize=14)\n",
    "plt.xlabel('Actual Log(Total Resolution Hours)', fontsize=12)\n",
    "plt.ylabel('Absolute Error', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{viz_dir}/error_magnitude_analysis.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 11. CONCLUSION AND RECOMMENDATIONS\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Based on the paper by Chai and Draxler, provide recommendations\n",
    "print(\"\\n=== METRIC SELECTION RECOMMENDATIONS ===\")\n",
    "print(\"Based on the error distribution analysis and the paper by Chai & Draxler (2014):\")\n",
    "\n",
    "# Check if errors are approximately normal (using Shapiro-Wilk test)\n",
    "_, ridge_p_value = stats.shapiro(ridge_errors)\n",
    "_, rf_p_value = stats.shapiro(rf_errors)\n",
    "\n",
    "print(f\"\\nNormality Test (Shapiro-Wilk):\")\n",
    "print(f\"Ridge Model: p-value = {ridge_p_value:.6f} ({'Normal' if ridge_p_value > 0.05 else 'Non-normal'} distribution)\")\n",
    "print(f\"Random Forest Model: p-value = {rf_p_value:.6f} ({'Normal' if rf_p_value > 0.05 else 'Non-normal'} distribution)\")\n",
    "\n",
    "print(\"\\nRecommended Metrics:\")\n",
    "if ridge_p_value > 0.05:\n",
    "    print(\"- For Ridge Model: RMSE is appropriate (errors follow normal distribution)\")\n",
    "else:\n",
    "    print(\"- For Ridge Model: MAE may be more appropriate (errors don't follow normal distribution)\")\n",
    "\n",
    "if rf_p_value > 0.05:\n",
    "    print(\"- For Random Forest Model: RMSE is appropriate (errors follow normal distribution)\")\n",
    "else:\n",
    "    print(\"- For Random Forest Model: MAE may be more appropriate (errors don't follow normal distribution)\")\n",
    "\n",
    "print(\"\\nOverall Recommendation:\")\n",
    "print(\"- Use multiple metrics (RMSE, MAE, and R²) to provide a complete picture\")\n",
    "print(\"- Report RMSE/MAE ratio to give insight into error distribution\")\n",
    "print(\"- Consider log-space metrics for model comparison (more stable distribution)\")\n",
    "print(\"- Use original-space metrics for practical interpretation of results\")\n",
    "\n",
    "print(f\"\\nAnalysis complete! All visualizations saved to {viz_dir}/\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
